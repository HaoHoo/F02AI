{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从零开始AI - 认知服务 - 计算机视觉\n",
    "\n",
    "> ··· 您可以访问 [https://github.com/HaoHoo/F02AI](https://github.com/HaoHoo/F02AI) 来获得 “从零开始AI” 系列全部的内容。··· <br>\n",
    ">`请以原样使用或转发，欢迎Issue，敬请PR；如果觉得有些意思，欢迎Fork，敬谢Star。` \n",
    "\n",
    "说起从零开始AI，使用Azure的认知服务算是一个再方便不过的方式了。认知服务使用标准REST \n",
    "API提供服务接口，这意味着开发者即使还没开始学习有关的人工智能代码，也可以在自己的应用中马上引入人工智能的能力。\n",
    "\n",
    "认知服务分为几大类，其中计算机视觉是非常重要的一个类别。实际上计算机对图片的识别速度和准确度已经超过了人类，所以我们看看计算机能用这个能力做些什么，也是一件非常有趣的事。\n",
    "\n",
    "按照现有提供的计算机视觉的分类，接下来我们可以尝试如下几种能力：\n",
    "* [图像分析](#AnalyzeImage)\n",
    "* [使用特定领域模型](#DomainSpecificModel)\n",
    "* [智能生成缩略图](#GetThumbnail)\n",
    "* [识别图中的印刷文字](#OCR)\n",
    "* [识别图中的手写文字](#RecognizeText)\n",
    "* [分析保存在本地的图片](#AnalyzeImageOnDisk)\n",
    "\n",
    "和其他认知服务一样，计算机视觉也是运行在Azure的服务。为了使用Computer Vision API，您需要一个订阅密钥 (subscription key)。别担心，您可以在[这里](https://docs.microsoft.com/azure/cognitive-services/Computer-vision/Vision-API-How-to-Topics/HowToSubscribe)获取免费的订阅密钥。\n",
    "\n",
    "获取订阅密钥后，请记录密钥及分配的Azure服务区域。对于测试认知服务，往往会分配美国中西区域 (WestCentralUS)。后面我们使用这些API时，必须提供这两种信息。\n",
    "\n",
    "## 使用Python调用Computer Vision API进行图像分析 <a name=\"AnalyzeImage\"> </a>\n",
    "\n",
    "在 [Analyze Image 方法](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa) API网站，您能够直接在页面查看图像分析所支持的方法。该 API 网站非常便利，除了查阅 API 方法之外，您还可以直接尝试提供图片测试该 API。如果调用成功，API 将返回以下信息:\n",
    "* 与图像内容相关的标签的详细列表。\n",
    "* 对图像内容的一个完整句子的描述。\n",
    "* 图像中包含的任何脸部的坐标、性别和年龄。\n",
    "* 图像类型（剪贴画或线条图）。\n",
    "* 主色、强调色或图像是否为黑白。\n",
    "* 在[分类](https://docs.microsoft.com/azure/cognitive-services/computer-vision/category-taxonomy)中定义的类别。\n",
    "* 图像是否包含成人或性暗示内容？\n",
    "\n",
    "### 分析图像\n",
    "要开始尝试使用计算机视觉服务分析图像，需要将下列代码中 `subscription_key` 的值 None 替换为前面我们获得的API密钥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = 'cd118d05c4c947ce95213bedcc8ba057'\n",
    "assert subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，请确认以下 `vision_base_url` 显示的地址与之前申请 API 密钥的区域吻合 (`westus`, `westcentralus`, 等等)。如果使用的是免费的订阅，通常不需要修改以下的地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_base_url = \"https://westus.api.cognitive.microsoft.com/vision/v2.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像分析的URL调用链接形如以下的例子 (可以在[这里](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa)查看REST API文档):\n",
    "<code>\n",
    "https://[location].api.cognitive.microsoft.com/vision/v2.0/<b>analyze</b>[?visualFeatures][&details][&language]\n",
    "</code>\n",
    "因为我们首先尝试图像分析，所以URL后面调用的功能为 `analyze`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_analyze_url = vision_base_url + \"analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要开始分析图像，我们需要提供一张图片的URL给 `image_url` 变量。\n",
    "您可以点击显示的图片链接来查看原始图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://github.com/HaoHoo/F02AI/raw/master/N02/images/Vision/ljz.jpeg\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了通过 REST 方式调用计算机视觉 `analyze` API，接下来的代码块需要使用 Python 的 `requests` 库。API 调用的结果将以 JSON 对象返回。按照规范，变量 `headers` 使用一个 dictionary 类型来包含必要的 API 密钥信息。而变量 `params` 同样使用 dictionary 类型来定义要调用的可视化功能，在这里我们选择三个功能  Categories,Description,Color 来尝试。所有支持的功能都可以访问 [REST API 文档](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa)查看。\n",
    "\n",
    "接着就可以通过 `requests` 来调用 REST 并返回 JSON 形式的结果了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "params   = {'visualFeatures': 'Categories,Description,Color'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "analysis = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`analysis` 对象包含了很多个变量域来描述分析的图像。图像最相关的标题可以从 `descriptions` 属性中获得。我们可以把描述从 JSON 中挑选出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "print(image_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码行显示您提供的图像，并用推断出的标题标记在图像上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "_ = plt.title(image_caption, size=\"x-large\", y=-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用特定领域模型 <a name=\"DomainSpecificModel\"> </a>\n",
    "\n",
    "[特定领域模型](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fd) 是一个训练用来识别图像中特定对象集的模型。当前可用的两个特定于域的模型是_名人_(_celebrities_)和_地标_(_landmarks_). \n",
    "\n",
    "要查看受支持的特定于域的模型的列表，可以针对该服务发出以下请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = vision_base_url + \"models\"\n",
    "headers   = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "models    = requests.get(model_url, headers=headers).json()\n",
    "[model[\"name\"] for model in models[\"models\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 地标识别\n",
    "要开始使用特定领域的地标模型，请将 `image_url` 设置为指向要分析的图像。\n",
    "同样，我们可以点击输出的链接查看原始图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/HaoHoo/F02AI/raw/master/N02/images/Vision/ljz.jpeg\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://github.com/HaoHoo/F02AI/raw/master/N02/images/Vision/tam.jpeg\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下构造图像分析服务的终结点调用结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_analyze_url = vision_base_url + \"models/landmarks/analyze\"\n",
    "print(landmark_analyze_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在 `image_url` 所指定的图片能够被分析为地标。识别出的地标描述将保存在 `landmark_name` 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params   = {'model': 'landmarks'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(landmark_analyze_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis      = response.json()\n",
    "assert analysis[\"result\"][\"landmarks\"] is not []\n",
    "\n",
    "landmark_name = analysis[\"result\"][\"landmarks\"][0][\"name\"].capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "_ = plt.title(landmark_name, size=\"x-large\", y=-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 名人识别\n",
    "同样，可以调用特定于领域的名人识别模型，如下所示。第一组 `image_url` 指向名人的图片。点击输出的链接，可以查看原始的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/HaoHoo/F02AI/master/N02/images/Vision/BillG.jpg\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/HaoHoo/F02AI/master/N02/images/Vision/BillG.jpg\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "识别名人的服务终结点的调用构造如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_analyze_url = vision_base_url + \"models/celebrities/analyze\"\n",
    "print(celebrity_analyze_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后， `image_url` 指定的[图片](https://upload.wikimedia.org/wikipedia/commons/d/d9/Bill_gates_portrait.jpg)中的名人将被识别出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params   = {'model': 'celebrities'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(celebrity_analyze_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析结果如上返回名人的信息，例如面部位置、名字、可行度等等。如果图片中识别出了名人，接下来的代码将从结果中获取名人相关的信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis[\"result\"][\"celebrities\"] is not []\n",
    "celebrity_info = analysis[\"result\"][\"celebrities\"][0]\n",
    "celebrity_name = celebrity_info[\"name\"]\n",
    "celebrity_face = celebrity_info[\"faceRectangle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们可以使用返回的信息，在图片上标记名人的脸并加上注释："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "image  = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax     = plt.imshow(image, alpha=0.6)\n",
    "origin = (celebrity_face[\"left\"], celebrity_face[\"top\"])\n",
    "p      = Rectangle(origin, celebrity_face[\"width\"], celebrity_face[\"height\"], \n",
    "                   fill=False, linewidth=2, color='b')\n",
    "ax.axes.add_patch(p)\n",
    "plt.text(origin[0], origin[1], celebrity_name, fontsize=20, weight=\"bold\", va=\"bottom\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Computer Vision API 获取缩略图<a name=\"GetThumbnail\"> </a>\n",
    "\n",
    "使用 [获取缩略图](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fb) 可以对图片按照兴趣区域 (ROI, region of interest)，使用您期望的长宽进行裁剪。为缩略图设置的纵横比可以不同于输入图像的纵横比。\n",
    "\n",
    "为一张图片生成缩略图，首先提供图片的位置 `image_url` 。同样，我们可以点击输出的链接查看原图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/9/94/Bloodhound_Puppy.jpg\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原图生成缩略图的服务终结点可按如下构造："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_url = vision_base_url + \"generateThumbnail\"\n",
    "print(thumbnail_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们尝试生成一个50x50像素的缩略图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params   = {'width': '50', 'height': '50','smartCropping': 'true'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(thumbnail_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以使用 Python Image 库来验证缩略图的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = Image.open(BytesIO(response.content))\n",
    "print(\"Thumbnail is {0}x{1}\".format(*thumbnail.size))\n",
    "thumbnail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  使用 Computer Vision API 进行 OCR<a name=\"OCR\"> </a>\n",
    "\n",
    "[OCR 方法](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fc) (Optical Character Recognition) 同步检测图像中的打印文本，并将识别字符提取到机器可用的字符流中。\n",
    "\n",
    "要尝试 OCR API，请将 `image_url` 设置为指向要识别文本的图片。可以点击输出的链接查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Atomist_quote_from_Democritus.png/338px-Atomist_quote_from_Democritus.png\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR所对应的服务服务终结点可构造如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_url = vision_base_url + \"ocr\"\n",
    "print(ocr_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，您可以调用 OCR 服务来获取与边界框一起识别的文本。在显示的参数中， `\"language\": \"unk\"` 自动检测文本语言， `\"detectOrientation\": \"true\"` 自动对齐图片。更多的参数可以查看 [REST API 文档](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fc)查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params   = {'language': 'unk', 'detectOrientation ': 'true'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用以下代码行从分析结果中提取单词边界框和文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "word_infos = []\n",
    "for line in line_infos:\n",
    "    for word_metadata in line:\n",
    "        for word_info in word_metadata[\"words\"]:\n",
    "            word_infos.append(word_info)\n",
    "word_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果能看到，对于被识别出的文字，OCR 服务给出了图片中文字的范围和识别出的文字内容。让我们使用 `matplotlib` 库来将这些内容显示在图片中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "image  = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax     = plt.imshow(image, alpha=0.5)\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch  = Rectangle(origin, bbox[2], bbox[3], fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Computer Vision API 识别文字 <a name=\"RecognizeText\"> </a>\n",
    "\n",
    "使用 [Recognize Text 方法](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/587f2c6a154055056008f200) 异步检测图像中的手写或打印文本，并将识别的字符提取到机器可用的字符流中。\n",
    "\n",
    "通过 `image_url` 提供将被识别的图片。输出的链接可以直接查看原图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Cursive_Writing_on_Notebook_paper.jpg/800px-Cursive_Writing_on_Notebook_paper.jpg\"\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "服务终结点可以按照如下代码进行构造："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_recognition_url = vision_base_url + \"recognizeText\"\n",
    "print(text_recognition_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手写文本识别服务可用于识别图像中的文本。在 `params` dictionary 参数中，除了我们尝试的手写文字，您能够设置类型 `mode` 为 `Printed` 来识别打印的文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params   = {'mode' : 'Handwritten'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(text_recognition_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，文本识别服务不会自行、立刻返回已识别的文本。相反，它会在响应头中立即返回一个 `operation_url` 的 URL，必须对其进行轮询才能获得操作结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_url = response.headers[\"Operation-Location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取 `operation_url` 后，可以查询分析文本。以下代码行实现一个轮询循环，以等待操作完成。注意，轮询是通过 HTTP的 `get` 方法而不是 `post` 来完成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "analysis = {}\n",
    "while not \"recognitionResult\" in analysis:\n",
    "    response_final = requests.get(response.headers[\"Operation-Location\"], headers=headers)\n",
    "    analysis       = response_final.json()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，可以提取识别的文本以及边界框，如下面的代码行所示。需要注意的一点是，手写文本识别API将边界框返回为**多边形**，而不是**矩形**。每个多边形由其顶点定义，使用以下约定：\n",
    "\n",
    "<i>p</i> = [<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>, ..., <i>x</i><sub>N</sub>, <i>y</i><sub>N</sub>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = [(line[\"boundingBox\"], line[\"text\"]) for line in analysis[\"recognitionResult\"][\"lines\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，利用提取的多边形信息将识别出的文本覆盖在原始图像的顶部。请注意，`matplotlib` 库要求将顶点指定为表单的元组列表：\n",
    "\n",
    "<i>p</i> = [(<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>), (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>), ..., (<i>x</i><sub>N</sub>, <i>y</i><sub>N</sub>)]\n",
    "\n",
    "处理代码将返回的多边形数据转换为 `matplotlib` 所需的格式，并在原始图片上标记识别的文字范围和识别结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "image  = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax     = plt.imshow(image)\n",
    "for polygon in polygons:\n",
    "    vertices = [(polygon[0][i], polygon[0][i+1]) for i in range(0,len(polygon[0]),2)]\n",
    "    text     = polygon[1]\n",
    "    patch    = Polygon(vertices, closed=True,fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(vertices[0][0], vertices[0][1], text, fontsize=20, va=\"top\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析保存在本地的图片 <a name=\"AnalyzeImageOnDisk\"> </a>\n",
    "\n",
    "Computer Vision REST API 不仅接受公共可访问图像的 URL，还可作为 HTTP 主体的一部分来提供要分析的图像。有关此功能的模式详细信息，请参阅[文档](https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa). \n",
    "\n",
    "本节中的代码使用此功能分析磁盘上的示例图像。传递图像 URL 与传递图像数据的主要区别在于，请求的头必须包含表单的条目：\n",
    "```py\n",
    "{\"Content-Type\": \"application/octet-stream\"}\n",
    "```\n",
    "二进制图像数据必须通过 `data` 参数传递给 `requests.post`，而不是 `json` 参数。\n",
    "\n",
    "首先，以下代码会从微软 [Computer Vision API](https://azure.microsoft.com/services/cognitive-services/computer-vision/) 示范网页下载一张图片，下载到本地（即本 notebook 运行的环境）的图片将会使用变量 `image_path` 来提供访问路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p images\n",
    "curl -Ls https://aka.ms/csnb-house-yard -o images/house_yard.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些代码使用 `bash` 来执行获取 https://aka.ms/csnb-house-yard 这个短链接所代表的图片链接，然后保存在创建的 images 目录中。当然，您也可以将其换成自己的图片的链接地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"images/house_yard.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们把这张图片读取到一个字节队列（byte array）中，并发送到计算机视觉服务进行分析，并输出分析的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = open(image_path, \"rb\").read()\n",
    "headers    = {'Ocp-Apim-Subscription-Key': subscription_key, \n",
    "              \"Content-Type\": \"application/octet-stream\" }\n",
    "params     = {'visualFeatures': 'Categories,Description,Color'}\n",
    "response   = requests.post(vision_analyze_url, \n",
    "                           headers=headers, \n",
    "                           params=params, \n",
    "                           data=image_data)\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis      = response.json()\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "image_caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和前文一样，利用代码，标题可以很容易地覆盖在图像上。请注意，由于图像已经在本地可用，因此该过程比之前略短。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "_ = plt.title(image_caption, size=\"x-large\", y=-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "ms_docs_meta": {
   "author": "JuliaNik",
   "description": "Get information and code samples to help you quickly get started using Python and the Computer Vision API in Microsoft Cognitive Services.",
   "manager": "ytkuo",
   "ms.author": "juliakuz",
   "ms.date": "02/02/2018",
   "ms.service": "cognitive-services",
   "ms.technology": "computer-vision",
   "ms.topic": "article",
   "services": "cognitive-services",
   "title": "Computer Vision API Python quick start | Microsoft Docs",
   "titleSuffix": "Computer Vision API Python quick start | Microsoft Cognitive Services"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
